{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cdcb49-3cf2-4d38-8664-fc4a3804e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import regularizers\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e64732-d49c-4283-adc3-86552a2c25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d554d1-5983-48a3-aee0-cbbbcf23cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../while_waiting_for_store.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf39be3-98f5-41f2-862d-9e179a86e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reset_index(drop=True)\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b35b76-2632-4a62-a117-58d7c8ae5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143c3cb-3086-4df0-8c7b-410c36b977ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642743a-be39-4671-9cb9-6befdbdd23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=32\n",
    "sentences=data['selftext']\n",
    "labels=data['relevance']\n",
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2fd53-31e6-49a6-9614-b84338471493",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b40959-c760-475e-9e3d-47776b2da8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape = (max_len,), dtype='int64')\n",
    "    masks= Input(shape = (max_len,), dtype='int64')\n",
    "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
    "    dense = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
    "    dropout= Dropout(0.5)(dense)\n",
    "    pred = Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
    "    print(model.summary())\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b2f34-946c-4751-9904-59683e233499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55a0bd-f9c5-4104-b657-0455f0b27bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    input_ids.append(dbert_inps['input_ids'])\n",
    "    attention_masks.append(dbert_inps['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8644f-b8c4-43c7-9c99-c4b00726dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./data/dbert_inp.pkl'\n",
    "pickle_mask_path='./data/dbert_mask.pkl'\n",
    "pickle_label_path='./data/dbert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63058082-85c3-471f-ab3b-349faa606bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce2b35-78d4-41f2-a8a0-1e560efe3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class_dict={0:'relevant',1:'spam'}\n",
    "target_names=label_class_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10d416-3265-409d-8382-c0163a9f2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))\n",
    "\n",
    "\n",
    "log_dir='dbert_model'\n",
    "model_save_path='./dbert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a70a5-471e-4770-9bc8-5f9dccb4a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066a071-11e8-4273-90ce-6a5704c44bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit([train_inp,train_mask],train_label,batch_size=16,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80d31c-cbce-45b4-abe3-4140e9e8ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3d25e-438a-4925-9eb9-0b95916e2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc511486-88e2-409d-8b71-02f697544366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46213b-3c6b-44b5-8992-85c5c847cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = create_model()\n",
    "trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
    "trained_model.load_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11843a0-f671-4b82-b8f7-15fd377eeba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trained_model.predict([val_inp,val_mask],batch_size=16)\n",
    "pred_labels = preds.argmax(axis=1)\n",
    "f1 = f1_score(val_label,pred_labels)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05659ac-8d27-4d88-a7e3-6561b29e4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=['ham','spam']\n",
    "print('F1 score',f1)\n",
    "print('Classification Report')\n",
    "print(classification_report(val_label,pred_labels,target_names=target_names))\n",
    "\n",
    "print('Training and saving built model.....')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afb1f9-0667-41d0-9819-0e599c18d25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
